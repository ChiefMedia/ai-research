{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353054ca",
   "metadata": {},
   "source": [
    "# Research with Gemini\n",
    "\n",
    "We're going to be testing Google's Gemini API. \n",
    "\n",
    "Credentials are located in config.yaml in the ai-research root folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1599ee",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e888abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from chiefai.ai import make_gemini_request\n",
    "from chiefai.db import query\n",
    "import polars as pl\n",
    "\n",
    "# Notebook formatting\n",
    "from IPython.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f6420d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 37)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>core_client</th><th>project_id</th><th>user_id</th><th>session_id</th><th>unique_key</th><th>postal_code</th><th>region</th><th>dma</th><th>dma_code</th><th>city</th><th>country</th><th>browser</th><th>device</th><th>device_type</th><th>search_engine</th><th>medium</th><th>source</th><th>platform</th><th>platform_version</th><th>bounce</th><th>session_date_time</th><th>ip_address</th><th>pages</th><th>search_terms</th><th>language</th><th>latitude</th><th>longitude</th><th>organization</th><th>referrer</th><th>session_length</th><th>created_at</th><th>updated_at</th><th>core_product</th><th>last_access</th><th>content</th><th>session</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td><td>str</td><td>list[struct[2]]</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>datetime[μs]</td><td>datetime[μs]</td><td>str</td><td>datetime[μs]</td><td>null</td><td>null</td></tr></thead><tbody><tr><td>99735578</td><td>&quot;OPOS&quot;</td><td>82884616</td><td>&quot;50182511673882&quot;</td><td>&quot;3288761085059530754&quot;</td><td>&quot;828846165018251167388232887610…</td><td>null</td><td>null</td><td>null</td><td>0</td><td>null</td><td>&quot;USA&quot;</td><td>&quot;Unknown&quot;</td><td>null</td><td>&quot;Desktop/laptop&quot;</td><td>null</td><td>&quot;paidsocial&quot;</td><td>&quot;snapchat&quot;</td><td>&quot;Unknown&quot;</td><td>&quot;Unknown&quot;</td><td>&quot;true&quot;</td><td>2024-01-03 13:11:13</td><td>&quot;34.123.204.87&quot;</td><td>[{&quot;collections/vaginal-health&quot;,0}]</td><td>null</td><td>&quot;Unknown&quot;</td><td>37.751</td><td>-97.822</td><td>&quot;Google&quot;</td><td>&quot;Direct&quot;</td><td>&quot;0&quot;</td><td>2024-01-03 13:13:00.337214</td><td>2024-01-03 13:13:00.337784</td><td>&quot;&quot;</td><td>2024-01-03 13:11:13</td><td>null</td><td>null</td></tr><tr><td>99735579</td><td>&quot;OPOS&quot;</td><td>82884616</td><td>&quot;78135251450464&quot;</td><td>&quot;5120671839057608705&quot;</td><td>&quot;828846167813525145046451206718…</td><td>&quot;32163&quot;</td><td>&quot;Florida&quot;</td><td>&quot;Orlando, FL&quot;</td><td>534</td><td>&quot;The Villages&quot;</td><td>&quot;USA&quot;</td><td>&quot;Safari&quot;</td><td>&quot;Apple iPhone&quot;</td><td>&quot;Mobile&quot;</td><td>null</td><td>&quot;paidsocial&quot;</td><td>&quot;ig&quot;</td><td>&quot;iOS&quot;</td><td>&quot;iOS 17.1&quot;</td><td>&quot;true&quot;</td><td>2024-01-03 13:11:13</td><td>&quot;68.205.39.5&quot;</td><td>[{&quot;collections/vaginal-health&quot;,0}]</td><td>null</td><td>&quot;English (United States)&quot;</td><td>28.9265</td><td>-81.9928</td><td>&quot;Spectrum&quot;</td><td>&quot;instagram.com&quot;</td><td>&quot;0&quot;</td><td>2024-01-03 13:13:00.337214</td><td>2024-01-03 13:13:00.337784</td><td>&quot;&quot;</td><td>2024-01-03 13:11:13</td><td>null</td><td>null</td></tr><tr><td>99735580</td><td>&quot;OPOS&quot;</td><td>82884616</td><td>&quot;103390995781948&quot;</td><td>&quot;6775832299565744285&quot;</td><td>&quot;828846161033909957819486775832…</td><td>null</td><td>null</td><td>null</td><td>0</td><td>null</td><td>&quot;USA&quot;</td><td>&quot;Chrome&quot;</td><td>&quot;Generic Android&quot;</td><td>&quot;Mobile&quot;</td><td>null</td><td>null</td><td>&quot;Direct&quot;</td><td>&quot;Android&quot;</td><td>&quot;Android 9.0&quot;</td><td>&quot;true&quot;</td><td>2024-01-03 13:11:13</td><td>&quot;147.160.184.123&quot;</td><td>[{&quot;tools/recurring/login&quot;,0}]</td><td>null</td><td>&quot;English (United States)&quot;</td><td>37.751</td><td>-97.822</td><td>&quot;Unknown&quot;</td><td>&quot;Direct&quot;</td><td>&quot;0&quot;</td><td>2024-01-03 13:13:00.337214</td><td>2024-01-03 13:13:00.337784</td><td>&quot;&quot;</td><td>2024-01-03 13:11:13</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 37)\n",
       "┌──────────┬────────────┬────────────┬────────────┬───┬────────────┬───────────┬─────────┬─────────┐\n",
       "│ id       ┆ core_clien ┆ project_id ┆ user_id    ┆ … ┆ core_produ ┆ last_acce ┆ content ┆ session │\n",
       "│ ---      ┆ t          ┆ ---        ┆ ---        ┆   ┆ ct         ┆ ss        ┆ ---     ┆ ---     │\n",
       "│ i64      ┆ ---        ┆ i64        ┆ str        ┆   ┆ ---        ┆ ---       ┆ null    ┆ null    │\n",
       "│          ┆ str        ┆            ┆            ┆   ┆ str        ┆ datetime[ ┆         ┆         │\n",
       "│          ┆            ┆            ┆            ┆   ┆            ┆ μs]       ┆         ┆         │\n",
       "╞══════════╪════════════╪════════════╪════════════╪═══╪════════════╪═══════════╪═════════╪═════════╡\n",
       "│ 99735578 ┆ OPOS       ┆ 82884616   ┆ 5018251167 ┆ … ┆            ┆ 2024-01-0 ┆ null    ┆ null    │\n",
       "│          ┆            ┆            ┆ 3882       ┆   ┆            ┆ 3         ┆         ┆         │\n",
       "│          ┆            ┆            ┆            ┆   ┆            ┆ 13:11:13  ┆         ┆         │\n",
       "│ 99735579 ┆ OPOS       ┆ 82884616   ┆ 7813525145 ┆ … ┆            ┆ 2024-01-0 ┆ null    ┆ null    │\n",
       "│          ┆            ┆            ┆ 0464       ┆   ┆            ┆ 3         ┆         ┆         │\n",
       "│          ┆            ┆            ┆            ┆   ┆            ┆ 13:11:13  ┆         ┆         │\n",
       "│ 99735580 ┆ OPOS       ┆ 82884616   ┆ 1033909957 ┆ … ┆            ┆ 2024-01-0 ┆ null    ┆ null    │\n",
       "│          ┆            ┆            ┆ 81948      ┆   ┆            ┆ 3         ┆         ┆         │\n",
       "│          ┆            ┆            ┆            ┆   ┆            ┆ 13:11:13  ┆         ┆         │\n",
       "└──────────┴────────────┴────────────┴────────────┴───┴────────────┴───────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = query(\"SELECT * FROM web_visit_results LIMIT 5\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87173c2c",
   "metadata": {},
   "source": [
    "## Assess AI Approach to Data Analysis\n",
    "\n",
    "We're going to use the make_gemini_request function in chiefmedai.ai to send data. \n",
    "\n",
    "The approach we're going to try is to create summary statistics from the database and programmatically generate a text query to feed to the AI model. We'll use prompt injection of the data to do this. \n",
    "\n",
    "Firstly we'll try getting simple counts of orders by platform and ask the AI model to assess the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d1f0e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "┌─────────────────────┬─────────┐\n",
      "│ source              ┆ revenue │\n",
      "│ ---                 ┆ ---     │\n",
      "│ str                 ┆ f64     │\n",
      "╞═════════════════════╪═════════╡\n",
      "│ portal.afterpay.com ┆ 180.08  │\n",
      "│ instagram.com       ┆ 38.73   │\n",
      "│ google              ┆ 45.47   │\n",
      "└─────────────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "orders_query = \"\"\"\n",
    "    SELECT\n",
    "        source,\n",
    "        revenue::NUMERIC\n",
    "    FROM web_event_results\n",
    "    WHERE \n",
    "        LOWER(event_name) = 'order'\n",
    "        AND event_date_time >= NOW() - INTERVAL '3 days' \n",
    "        AND core_client = 'OPOS'\n",
    "        AND core_product = 'MENO'\n",
    "    LIMIT 1000\n",
    "\"\"\"\n",
    "orders = query(orders_query)\n",
    "orders = orders.with_columns(\n",
    "    pl.col(\"revenue\").cast(pl.Float64).alias(\"revenue\")\n",
    ")\n",
    "print(orders.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15510f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>source</th><th>source_count</th><th>median_revenue</th><th>mean_revenue</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;instagram.com&quot;</td><td>81</td><td>32.18</td><td>43.182222</td></tr><tr><td>&quot;Direct&quot;</td><td>193</td><td>34.43</td><td>50.141088</td></tr><tr><td>&quot;google&quot;</td><td>321</td><td>31.3</td><td>40.197726</td></tr><tr><td>&quot;fb&quot;</td><td>148</td><td>36.98</td><td>44.272973</td></tr><tr><td>&quot;Klaviyo&quot;</td><td>50</td><td>33.325</td><td>46.5504</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────────────┬──────────────┬────────────────┬──────────────┐\n",
       "│ source        ┆ source_count ┆ median_revenue ┆ mean_revenue │\n",
       "│ ---           ┆ ---          ┆ ---            ┆ ---          │\n",
       "│ str           ┆ u32          ┆ f64            ┆ f64          │\n",
       "╞═══════════════╪══════════════╪════════════════╪══════════════╡\n",
       "│ instagram.com ┆ 81           ┆ 32.18          ┆ 43.182222    │\n",
       "│ Direct        ┆ 193          ┆ 34.43          ┆ 50.141088    │\n",
       "│ google        ┆ 321          ┆ 31.3           ┆ 40.197726    │\n",
       "│ fb            ┆ 148          ┆ 36.98          ┆ 44.272973    │\n",
       "│ Klaviyo       ┆ 50           ┆ 33.325         ┆ 46.5504      │\n",
       "└───────────────┴──────────────┴────────────────┴──────────────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_agg = orders.group_by(\n",
    "    \"source\"\n",
    ").agg([\n",
    "    pl.count(\"revenue\").alias(\"source_count\"),\n",
    "    pl.median(\"revenue\").alias(\"median_revenue\"),\n",
    "    pl.mean(\"revenue\").alias(\"mean_revenue\")\n",
    "]).filter(\n",
    "    pl.col(\"source_count\") >= 30\n",
    ")\n",
    "orders_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_descriptive_prompt(\n",
    "    df, \n",
    "    group_cols, \n",
    "    currency_symbol=\"$\", \n",
    "    add_comparisons=True,\n",
    "    decimal_places=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate a descriptive text prompt from a dataframe with grouped statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : polars.DataFrame or pandas.DataFrame\n",
    "        The dataframe containing the grouped statistics\n",
    "    group_cols : list or str\n",
    "        Column name(s) that represent categorical groupings\n",
    "    stat_cols : dict\n",
    "        Dictionary mapping column names to their descriptions\n",
    "        Format: {'column_name': {'type': 'count|mean|median|sum|etc', 'label': 'custom label', 'format': 'currency|percent|number'}}\n",
    "    currency_symbol : str, optional\n",
    "        Symbol to use for currency formatting (default: \"$\")\n",
    "    add_comparisons : bool, optional\n",
    "        Whether to add comparisons between measures like mean and median (default: True)\n",
    "    decimal_places : int, optional\n",
    "        Number of decimal places to round numeric values (default: 2)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Formatted descriptive text suitable for an AI prompt\n",
    "    \"\"\"\n",
    "    # Convert group_cols to list if it's a string\n",
    "    if isinstance(group_cols, str):\n",
    "        group_cols = [group_cols]\n",
    "    \n",
    "    # Validate inputs\n",
    "    for col in group_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Group column '{col}' not found in dataframe\")\n",
    "    \n",
    "    for col in stat_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Statistic column '{col}' not found in dataframe\")\n",
    "    \n",
    "    # Start building the prompt\n",
    "    prompt_text = \"\"\n",
    "    \n",
    "    # Function to format values based on their type\n",
    "    def format_value(value, col_info):\n",
    "        value = round(value, decimal_places)\n",
    "        \n",
    "        if col_info.get('format') == 'currency':\n",
    "            return f\"{currency_symbol}{value:.{decimal_places}f}\"\n",
    "        elif col_info.get('format') == 'percent':\n",
    "            return f\"{value:.{decimal_places}f}%\"\n",
    "        else:\n",
    "            return f\"{value:.{decimal_places}f}\" if isinstance(value, float) else f\"{value}\"\n",
    "    \n",
    "    # Determine if we're using polars or pandas\n",
    "    is_polars = hasattr(df, 'iter_rows')\n",
    "    \n",
    "    # Iterate through rows\n",
    "    if is_polars:\n",
    "        rows = df.iter_rows(named=True)\n",
    "    else:  # pandas\n",
    "        rows = df.to_dict('records')\n",
    "    \n",
    "    for row in rows:\n",
    "        # Create the group description (e.g., \"Source: instagram.com\")\n",
    "        group_desc = \"\"\n",
    "        for col in group_cols:\n",
    "            label = col.replace('_', ' ').title()\n",
    "            group_desc += f\"{label}: {row[col]}\\n\"\n",
    "        \n",
    "        # Add the statistics descriptions\n",
    "        stats_desc = \"\"\n",
    "        mean_value = None\n",
    "        median_value = None\n",
    "        \n",
    "        for col, col_info in [col for col in df.columns if col not in group_cols].items():\n",
    "            # Get custom label or generate one from column name\n",
    "            label = col_info.get('label', col.replace('_', ' ').title())\n",
    "            \n",
    "            # Get the type of statistic\n",
    "            stat_type = col_info.get('type', '').lower()\n",
    "            \n",
    "            # Format the value\n",
    "            value = row[col]\n",
    "            formatted_value = format_value(value, col_info)\n",
    "            \n",
    "            # Save mean and median values for comparison if needed\n",
    "            if stat_type == 'mean':\n",
    "                mean_value = value\n",
    "            elif stat_type == 'median':\n",
    "                median_value = value\n",
    "            \n",
    "            # Create appropriate description based on type\n",
    "            if stat_type == 'count':\n",
    "                stats_desc += f\"There were {formatted_value} {label}.\\n\"\n",
    "            elif stat_type == 'mean':\n",
    "                stats_desc += f\"The average ({stat_type}) {label} was {formatted_value}.\\n\"\n",
    "            elif stat_type == 'median':\n",
    "                stats_desc += f\"The {stat_type} {label} was {formatted_value}.\\n\"\n",
    "            elif stat_type == 'sum':\n",
    "                stats_desc += f\"The total {label} was {formatted_value}.\\n\"\n",
    "            else:\n",
    "                stats_desc += f\"The {label} was {formatted_value}.\\n\"\n",
    "        \n",
    "        # Add comparison between mean and median if both exist and comparison is requested\n",
    "        if add_comparisons and mean_value is not None and median_value is not None:\n",
    "            if mean_value > median_value:\n",
    "                difference = round(mean_value - median_value, decimal_places)\n",
    "                format_info = next((info for col, info in stat_cols.items() if info.get('type') == 'mean'), {})\n",
    "                formatted_diff = format_value(difference, format_info)\n",
    "                stats_desc += f\"The mean is {formatted_diff} higher than the median, suggesting some high-value outlier values.\\n\"\n",
    "            elif median_value > mean_value:\n",
    "                difference = round(median_value - mean_value, decimal_places)\n",
    "                format_info = next((info for col, info in stat_cols.items() if info.get('type') == 'mean'), {})\n",
    "                formatted_diff = format_value(difference, format_info)\n",
    "                stats_desc += f\"The median is {formatted_diff} higher than the mean, suggesting some low-value outlier values.\\n\"\n",
    "            else:\n",
    "                stats_desc += f\"The mean and median are identical, suggesting a symmetrical distribution of values.\\n\"\n",
    "        \n",
    "        # Combine group and stats descriptions\n",
    "        section = group_desc + stats_desc + (\"-\" * 40 + \"\\n\")\n",
    "        prompt_text += section\n",
    "    \n",
    "    # Remove the final separator\n",
    "    prompt_text = prompt_text.rstrip(\"-\" * 40 + \"\\n\")\n",
    "    \n",
    "    # Add a summary\n",
    "    groups_count = len(list(rows))\n",
    "    if len(group_cols) == 1:\n",
    "        group_label = group_cols[0].replace('_', ' ').lower()\n",
    "        prompt_text += f\"\\n\\nSummary: Analyzed statistics for {groups_count} different {group_label}s.\"\n",
    "    else:\n",
    "        group_labels = [col.replace('_', ' ').lower() for col in group_cols]\n",
    "        group_desc = \", \".join(group_labels)\n",
    "        prompt_text += f\"\\n\\nSummary: Analyzed statistics for {groups_count} different groups based on {group_desc}.\"\n",
    "    \n",
    "    return prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff7b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_descriptive_prompt(\n",
    "    df=orders_agg,\n",
    "    group_cols=[\"source\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d766416a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated the following descriptive text:\n",
      "\n",
      "        Source: instagram.com\n",
      "        There were 81 orders from this source. \n",
      "        The median revenue per order was $32.18.\n",
      "        The average (mean) revenue per order was $43.18.\n",
      "    ----------------------------------------\n",
      "\n",
      "        Source: Direct\n",
      "        There were 193 orders from this source. \n",
      "        The median revenue per order was $34.43.\n",
      "        The average (mean) revenue per order was $50.14.\n",
      "    ----------------------------------------\n",
      "\n",
      "        Source: google\n",
      "        There were 321 orders from this source. \n",
      "        The median revenue per order was $31.30.\n",
      "        The average (mean) revenue per order was $40.20.\n",
      "    ----------------------------------------\n",
      "\n",
      "        Source: fb\n",
      "        There were 148 orders from this source. \n",
      "        The median revenue per order was $36.98.\n",
      "        The average (mean) revenue per order was $44.27.\n",
      "    ----------------------------------------\n",
      "\n",
      "        Source: Klaviyo\n",
      "        There were 50 orders from this source. \n",
      "        The median revenue per order was $33.33.\n",
      "        The average (mean) revenue per order was $46.55.\n",
      "    ----------------------------------------\n",
      "\n",
      "        Source: applovin\n",
      "        There were 33 orders from this source. \n",
      "        The median revenue per order was $34.43.\n",
      "        The average (mean) revenue per order was $41.30.\n",
      "    \n",
      "\n",
      "Summary: Analyzed revenue statistics for 6 different traffic sources.\n"
     ]
    }
   ],
   "source": [
    "prompt_data = \"\"\n",
    "\n",
    "for row in orders_agg.iter_rows(named=True):\n",
    "    source = row['source']\n",
    "    count = row['source_count']\n",
    "    median = round(row['median_revenue'], 2)\n",
    "    mean = round(row['mean_revenue'], 2)\n",
    "    \n",
    "    # Generate a descriptive paragraph for this source\n",
    "    source_description = f\"\"\"\n",
    "        Source: {source}\n",
    "        There were {count} orders from this source. \n",
    "        The median revenue per order was ${median:.2f}.\n",
    "        The average (mean) revenue per order was ${mean:.2f}.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a comparison of mean to median\n",
    "    \"\"\"\n",
    "    if mean > median:\n",
    "        difference = round(mean - median, 2)\n",
    "        source_description += f\"The mean is ${difference:.2f} higher than the median, suggesting some high-value outlier orders.\\n\"\n",
    "    elif median > mean:\n",
    "        difference = round(median - mean, 2)\n",
    "        source_description += f\"The median is ${difference:.2f} higher than the mean, suggesting some low-value outlier orders.\\n\"\n",
    "    else:\n",
    "        source_description += f\"The mean and median are identical, suggesting a symmetrical distribution of order values.\\n\"\n",
    "    \"\"\"\n",
    "        \n",
    "    # Add a separator between sources\n",
    "    source_description += \"-\" * 40 + \"\\n\"\n",
    "    \n",
    "    # Add this source's description to the overall text\n",
    "    prompt_data += source_description\n",
    "\n",
    "# Remove the final separator and add a summary\n",
    "prompt_data = prompt_data.rstrip(\"-\" * 40 + \"\\n\")\n",
    "prompt_data += f\"\\n\\nSummary: Analyzed revenue statistics for {len(orders_agg)} different traffic sources.\"\n",
    "\n",
    "print(\"Generated the following descriptive text:\")\n",
    "print(prompt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a11de82f",
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Test AI function\n",
    "prompt = f\"\"\"ArithmeticError\n",
    "I'm sharing revenue data from our e-commerce store, broken down by traffic source. The data includes order counts, median revenue, and mean revenue for each source.\n",
    "\n",
    "[ANALYTICS DATA]\n",
    "{prompt_data}\n",
    "\n",
    "Based on this information, please provide:\n",
    "\n",
    "1. A summary of our overall traffic and revenue patterns. Briefly mention volume, but you do not need to provide detail, since spending levels differ by channel.\n",
    "2. An analysis of which traffic sources are most valuable in terms of:\n",
    "   - Total revenue contribution\n",
    "   - Revenue per order\n",
    "   - Potential for growth based on order volume\n",
    "\n",
    "3. Insights about any outliers or unusual patterns in the data\n",
    "\n",
    "4. Strategic recommendations for:\n",
    "   - Which traffic sources we should invest more in\n",
    "   - Which sources might need optimization\n",
    "   - Any suggested A/B tests or experiments\n",
    "\n",
    "5. How our traffic source performance compares to typical e-commerce benchmarks\n",
    "\n",
    "Please format your analysis with clear sections and include both tactical and strategic insights. Feel free to note any additional data that would help refine this analysis further.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6211339e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's an analysis of your e-commerce traffic source revenue data, broken down into the sections you requested.\n",
       "\n",
       "## E-Commerce Traffic Source Revenue Analysis\n",
       "\n",
       "**1. Overall Traffic and Revenue Patterns Summary:**\n",
       "\n",
       "You're acquiring traffic from a variety of sources, including social media (Instagram, Facebook), direct traffic, search engines (Google), email marketing (Klaviyo), and potentially paid advertising networks (Applovin). There is significant variation in order volume across these channels. While deeper analysis is needed to assess net profit, it appears that your average order values are generally similar across channels.\n",
       "\n",
       "**2. Traffic Source Valuation:**\n",
       "\n",
       "*   **Total Revenue Contribution:**\n",
       "    To determine total revenue contribution, we would need to multiply order counts by the *average* revenue per order (since the mean reflects total spending better than median). Without that calculation explicitly done, we can still infer based on order volume and average revenue. I will assume the calculation is done and then present results as if you have the exact data:\n",
       "    *   **Google:** Likely has the highest total revenue contribution due to the large order volume (321).\n",
       "    *   **Direct:** Likely second highest due to second-highest order volume (193) and a higher-than-average revenue per order.\n",
       "    *   **Facebook:** Good total revenue contribution with a solid order volume (148).\n",
       "    *   **Instagram, Klaviyo, and Applovin:** contribute less total revenue due to lower order volumes.\n",
       "\n",
       "*   **Revenue Per Order (Average):**\n",
       "    *   **Direct:** Leads with the highest average revenue per order ($50.14).\n",
       "    *   **Klaviyo:** A close second, at $46.55 per order. This makes intuitive sense as email-driven traffic is more likely to come from engaged customers.\n",
       "    *   **Facebook:** Follows at $44.27 per order.\n",
       "    *   **Instagram:** $43.18 per order.\n",
       "    *   **Applovin:** At $41.30, the lowest average revenue.\n",
       "    *   **Google:** Near the bottom at $40.20 per order.\n",
       "\n",
       "*   **Potential for Growth Based on Order Volume:**\n",
       "\n",
       "    *   **Google:** Has the *highest* potential because you already have a substantial volume. Even small improvements in conversion rate or average order value can translate to significant revenue gains.\n",
       "    *   **Facebook:** Significant growth potential due to a relatively high order volume and competitive average revenue per order.\n",
       "    *   **Instagram:** Solid growth potential due to moderate order volume and decent average revenue per order.\n",
       "    *   **Klaviyo & Applovin:** While they have lower order volumes, the high revenue per order (especially Klaviyo) indicates a highly valuable user base that could grow.\n",
       "\n",
       "**3. Outliers and Unusual Patterns:**\n",
       "\n",
       "*   **Direct Traffic Dominance in Average Revenue:** The Direct channel having the highest average revenue per order is noteworthy. This could indicate strong brand loyalty, effective offline marketing driving people directly to your site, or a segment of customers who are repeat purchasers. This is good, but requires more investigation.\n",
       "*   **Google's Lower Average Revenue Per Order:** Google having the *highest* order volume but one of the *lowest* average revenue per order values is another important signal. It is not unusual because high-volume channels often tend to be a bit less valuable due to targeting issues. It suggests that the keywords or targeting strategies used may be attracting a broader audience, not all of whom are high-value customers. The sheer volume still makes it important.\n",
       "*   **Applovin's Lower Volume/Revenue:** Applovin's revenue and volume are both quite low compared to the other sources.\n",
       "\n",
       "**4. Strategic Recommendations:**\n",
       "\n",
       "*   **Invest More In:**\n",
       "    *   **Google:** Given the high order volume, invest in optimizing Google Ads (or SEO) for more targeted keywords and higher-value customers. Even small improvements in conversion rate or AOV on Google will have a large impact on the bottom line.\n",
       "    *   **Direct:** Determine what is driving direct traffic and double down on that.\n",
       "    *   **Klaviyo:** Given the high revenue per order, focus on growing your email list and implementing more personalized email marketing campaigns.\n",
       "    *   **Facebook:** Continue investing in Facebook ads, focusing on refining targeting to improve average order value.\n",
       "\n",
       "*   **Optimize:**\n",
       "    *   **Applovin:** Evaluate the ROI of Applovin. Is the cost per acquisition (CPA) justified by the revenue generated? If not, consider pausing or optimizing the campaigns, or reevaluating its use in your stack.\n",
       "    *   **Google:** Implement A/B testing of landing pages and ad copy to increase average order value. Consider adding product recommendations, upsells, and bundles.\n",
       "    *   **Instagram:** Experiment with different types of content and calls to action to improve conversion rates and average order value.\n",
       "\n",
       "*   **Suggested A/B Tests and Experiments:**\n",
       "\n",
       "    *   **Google:**\n",
       "        *   **A/B Test:** Landing page variations focused on different product categories for specific keyword groups.\n",
       "        *   **Experiment:** Implement smart bidding strategies to optimize for value (revenue) rather than just clicks.\n",
       "        *   **Experiment:** Use data to personalize ad copy based on user demographics or search history.\n",
       "\n",
       "    *   **Facebook/Instagram:**\n",
       "        *   **A/B Test:** Ad creative with different value propositions (e.g., free shipping, exclusive discounts) to see what resonates best with your target audience.\n",
       "        *   **Experiment:** Test different targeting options (e.g., lookalike audiences, interest-based targeting) to find the most profitable segments.\n",
       "\n",
       "    *   **Klaviyo:**\n",
       "        *   **A/B Test:** Subject lines and email content to improve open and click-through rates.\n",
       "        *   **Experiment:** Segment email lists based on purchase history and behavior to deliver more personalized offers.\n",
       "    *   **Direct:**\n",
       "        *   **Experiment:** Add \"how did you hear about us\" section to checkout flow\n",
       "        *   **Experiment:** Survey customers on brand awareness/impressions\n",
       "\n",
       "**5. Comparison to E-Commerce Benchmarks:**\n",
       "\n",
       "It's difficult to give precise benchmarks without knowing your specific industry and product category. However, here are some general considerations:\n",
       "\n",
       "*   **Traffic Source Mix:** A healthy e-commerce business often has a mix of traffic sources. It's positive that you're not overly reliant on a single source.\n",
       "*   **Average Order Value (AOV):** The AOV benchmark varies widely. You should research AOV benchmarks specific to your industry. Compare your AOV across channels to see if any channels are significantly underperforming.\n",
       "*   **Conversion Rates:** Research average conversion rates for your industry and for each traffic source. This will help you identify areas where you can improve.\n",
       "*   **Direct Traffic:** A high percentage of direct traffic typically indicates strong brand recognition and customer loyalty, which is a positive sign. If it's *too* high, make sure referral traffic is actually being attributed to \"direct\" when it should be shown as other channels.\n",
       "\n",
       "**Additional Data Needs:**\n",
       "\n",
       "To refine this analysis further, I would need the following information:\n",
       "\n",
       "*   **Cost Data:** The cost of acquiring traffic from each source (e.g., ad spend, agency fees). This is *critical* to calculate ROI and make informed investment decisions.\n",
       "*   **Profit Margin:** Your average profit margin on each product. This will allow you to determine the true profitability of each traffic source.\n",
       "*   **Customer Lifetime Value (CLTV):** This is a crucial metric. Understanding which traffic sources bring in customers with the highest CLTV will help you prioritize long-term growth.\n",
       "*   **Attribution Modeling:** How do you attribute conversions to different traffic sources? Are you using a first-touch, last-touch, or multi-touch attribution model? The attribution model you use can significantly impact your understanding of which sources are most valuable.\n",
       "*   **Segmentation:** Can you segment your customer data by demographics, purchase history, or other factors? This would allow you to identify high-value customer segments and target them more effectively.\n",
       "*   **Return on Ad Spend (ROAS)** For advertising channels, it's important to know the returns you're getting.\n",
       "\n",
       "By incorporating this additional data, you can create a much more detailed and actionable analysis of your traffic source performance. Good luck!\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = make_gemini_request(request_text=prompt)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
